{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e8add34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9f53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1 MB)\n",
      "     ---------------------------------------- 7.1/7.1 MB 9.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\priyanka\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\priyanka\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     -------------------------------------- 307.0/307.0 kB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.0.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ef6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/Amazon-Musical-Reviews-Rating-Dataset/master/Musical_instruments_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3795bd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>A14B2YH83ZXMPP</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Lonnie M. Adams</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great, just as expected.  Thank to all.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1405814400</td>\n",
       "      <td>07 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>A1RPTVW5VEOSI</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Michael J. Edelman</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've been thinking about trying the Nanoweb st...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Long life, and for some players, a good econom...</td>\n",
       "      <td>1404259200</td>\n",
       "      <td>07 2, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>AWCJ12KBO5VII</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Michael L. Knapp</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I have tried coated strings in the past ( incl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good for coated.</td>\n",
       "      <td>1405987200</td>\n",
       "      <td>07 22, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>A2Z7S8B5U4PAKJ</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>Rick Langdon \"Scriptor\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Well, MADE by Elixir and DEVELOPED with Taylor...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Taylor Made</td>\n",
       "      <td>1404172800</td>\n",
       "      <td>07 1, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>A2WA8TDCTGUADI</td>\n",
       "      <td>B00JBIVXGC</td>\n",
       "      <td>TheTerrorBeyond</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These strings are really quite good, but I wou...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>These strings are really quite good, but I wou...</td>\n",
       "      <td>1405468800</td>\n",
       "      <td>07 16, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10261 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID        asin  \\\n",
       "0      A2IBPI20UZIR0U  1384719342   \n",
       "1      A14VAT5EAX3D9S  1384719342   \n",
       "2      A195EZSQDW3E21  1384719342   \n",
       "3      A2C00NNG1ZQQG2  1384719342   \n",
       "4       A94QU4C90B1AX  1384719342   \n",
       "...               ...         ...   \n",
       "10256  A14B2YH83ZXMPP  B00JBIVXGC   \n",
       "10257   A1RPTVW5VEOSI  B00JBIVXGC   \n",
       "10258   AWCJ12KBO5VII  B00JBIVXGC   \n",
       "10259  A2Z7S8B5U4PAKJ  B00JBIVXGC   \n",
       "10260  A2WA8TDCTGUADI  B00JBIVXGC   \n",
       "\n",
       "                                           reviewerName   helpful  \\\n",
       "0      cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                                  Jake  [13, 14]   \n",
       "2                         Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                             RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                         SEAN MASLANKA    [0, 0]   \n",
       "...                                                 ...       ...   \n",
       "10256                                   Lonnie M. Adams    [0, 0]   \n",
       "10257                                Michael J. Edelman    [0, 0]   \n",
       "10258                                  Michael L. Knapp    [0, 0]   \n",
       "10259                           Rick Langdon \"Scriptor\"    [0, 0]   \n",
       "10260                                   TheTerrorBeyond    [0, 0]   \n",
       "\n",
       "                                              reviewText  overall  \\\n",
       "0      Not much to write about here, but it does exac...      5.0   \n",
       "1      The product does exactly as it should and is q...      5.0   \n",
       "2      The primary job of this device is to block the...      5.0   \n",
       "3      Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4      This pop filter is great. It looks and perform...      5.0   \n",
       "...                                                  ...      ...   \n",
       "10256            Great, just as expected.  Thank to all.      5.0   \n",
       "10257  I've been thinking about trying the Nanoweb st...      5.0   \n",
       "10258  I have tried coated strings in the past ( incl...      4.0   \n",
       "10259  Well, MADE by Elixir and DEVELOPED with Taylor...      4.0   \n",
       "10260  These strings are really quite good, but I wou...      4.0   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "0                                                   good      1393545600   \n",
       "1                                                   Jake      1363392000   \n",
       "2                                   It Does The Job Well      1377648000   \n",
       "3                          GOOD WINDSCREEN FOR THE MONEY      1392336000   \n",
       "4                  No more pops when I record my vocals.      1392940800   \n",
       "...                                                  ...             ...   \n",
       "10256                                         Five Stars      1405814400   \n",
       "10257  Long life, and for some players, a good econom...      1404259200   \n",
       "10258                                   Good for coated.      1405987200   \n",
       "10259                                        Taylor Made      1404172800   \n",
       "10260  These strings are really quite good, but I wou...      1405468800   \n",
       "\n",
       "        reviewTime  \n",
       "0      02 28, 2014  \n",
       "1      03 16, 2013  \n",
       "2      08 28, 2013  \n",
       "3      02 14, 2014  \n",
       "4      02 21, 2014  \n",
       "...            ...  \n",
       "10256  07 20, 2014  \n",
       "10257   07 2, 2014  \n",
       "10258  07 22, 2014  \n",
       "10259   07 1, 2014  \n",
       "10260  07 16, 2014  \n",
       "\n",
       "[10261 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af641b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10261 entries, 0 to 10260\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   reviewerID      10261 non-null  object \n",
      " 1   asin            10261 non-null  object \n",
      " 2   reviewerName    10234 non-null  object \n",
      " 3   helpful         10261 non-null  object \n",
      " 4   reviewText      10254 non-null  object \n",
      " 5   overall         10261 non-null  float64\n",
      " 6   summary         10261 non-null  object \n",
      " 7   unixReviewTime  10261 non-null  int64  \n",
      " 8   reviewTime      10261 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 721.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdab033",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453e21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop rows with missing reviews\n",
    "    missing_review_rows = df[df['reviewText'].isna()].index\n",
    "    df = df.drop(missing_review_rows, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Use only the review and rating column\n",
    "    y = df['overall']\n",
    "    X = df['reviewText']\n",
    "    \n",
    "     # Make y a binary target\n",
    "    y = y.apply(lambda x: 1 if x == 5 else 0)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n",
    "    \n",
    "     # Learn the vocabulary\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "     # Find the size of the vocabulary\n",
    "    vocab_length = len(tokenizer.word_index) + 1\n",
    "    print(\"Vocab length:\", vocab_length)\n",
    "    \n",
    "    # Convert review texts into sequences of integers\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Find the maximum sequence length\n",
    "    max_seq_length = np.max(list(map(lambda x: len(x), X_train)))\n",
    "    print(\"Maximum sequence length:\", max_seq_length)\n",
    "    \n",
    "    # Pad the sequences to by uniform length\n",
    "    X_train = pad_sequences(X_train, maxlen=max_seq_length, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_seq_length, padding='post')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, vocab_length, max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a2440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 18268\n",
      "Maximum sequence length: 1830\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, VOCAB_LENGTH, MAX_SEQ_LENGTH = preprocess_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84847688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7177, 1830)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3e583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3077, 1830)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd9843",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f45ca1a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'pandas.core.series.Series'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14796\\2096629324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         )\n\u001b[0;32m     34\u001b[0m     ]\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1038\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[0;32m   1039\u001b[0m           data_adapter.train_validation_split(\n\u001b[1;32m-> 1040\u001b[1;33m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     raise ValueError(\n\u001b[0;32m   1375\u001b[0m         \u001b[1;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m         \"arrays, found following types in the input: {}\".format(unsplitable))\n\u001b[0m\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'pandas.core.series.Series'>]"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = tf.keras.layers.Embedding(\n",
    "    input_dim=VOCAB_LENGTH,\n",
    "    output_dim=128,\n",
    "    input_length=MAX_SEQ_LENGTH\n",
    ")(inputs)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975beca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
